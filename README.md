# ðŸª™ Crypto Data Pipeline: Extract, Transform & Load

## ðŸ“ DescriÃ§Ã£o do Projeto

Este projeto implementa um pipeline de dados automatizado para monitorar preÃ§os de criptomoedas em tempo real. O script realiza o scraping de dados do CoinMarketCap, processa as informaÃ§Ãµes para um formato estruturado e gerencia a persistÃªncia dos dados de forma incremental, garantindo que o histÃ³rico seja preservado sem sobrescritas.

Originalmente desenvolvido para Google Colab com integraÃ§Ã£o ao Google Drive, o projeto Ã© facilmente adaptÃ¡vel para execuÃ§Ã£o de jobs agendados em ambientes como Databricks ou instÃ¢ncias EC2.

## ðŸš€ Funcionalidades

    ExtraÃ§Ã£o: Captura de preÃ§os em tempo real via Web Scraping.

    TransformaÃ§Ã£o: Limpeza de strings (moeda/sÃ­mbolo) e padronizaÃ§Ã£o de fuso horÃ¡rio (BRT - UTC-3).

    Carga Incremental: LÃ³gica que verifica a existÃªncia de um histÃ³rico prÃ©vio e concatena novos dados.

    PersistÃªncia: Armazenamento resiliente em CSV com suporte a sistemas de arquivos em nuvem.

## ðŸ› ï¸ Tecnologias Utilizadas

    Linguagem: Python

    Bibliotecas de Dados: Pandas para manipulaÃ§Ã£o e estruturaÃ§Ã£o.

    Web Scraping: BeautifulSoup4 e requests.

    Time Management: pytz e datetime para gestÃ£o de fuso horÃ¡rio brasileiro.

    Cloud Storage: IntegraÃ§Ã£o com Google Drive (adaptÃ¡vel para DBFS/S3).

## ðŸ“ Estrutura do CÃ³digo

O projeto Ã© dividido em funÃ§Ãµes modulares seguindo os princÃ­pios de clean code:

    extract_dados(): Acessa a URL e isola o elemento HTML contendo o preÃ§o.

    trans_dados(): Formata os dados crus em um dicionÃ¡rio estruturado.

    data_atual() / hora_atual(): Garante o registro temporal correto no fuso America/Sao_Paulo.

    carga_dados(): Gerencia a inteligÃªncia do pipeline (Leitura -> ConcatenaÃ§Ã£o -> PersistÃªncia).

## ðŸ“ˆ Exemplo de Dados Capturados

|moeda|simbolo|preco|data|hora|
|Bitcoin|BTC|52140.50|09-02-2026|14:00:05|
|Ethereum|ETH|2850.12|09-02-2026|14:00:05|

## ðŸ”§ Como Executar

  **Clone o repositÃ³rio:**

    git clone https://github.com/seu-usuario/nome-do-repositorio.git

  **Instale as dependÃªncias:**

    pip install pandas requests beautifulsoup4 pytz

  **Configure o caminho do arquivo no script (path) para o seu diretÃ³rio local ou cloud.**

  **Execute o script principal para iniciar a coleta.**
